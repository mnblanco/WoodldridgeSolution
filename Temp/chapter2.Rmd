---
title: "Chapter 2: The simple regression Model"
author: "Marjorie Blanco"
date: "12/19/2018"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
# Clear environment
rm(list = ls(all = TRUE))
knitr::opts_chunk$set(echo = FALSE, message=FALSE, error=FALSE, warning=FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

# Clear environment
rm(list = ls(all = TRUE))
library(wooldridge)
library(dplyr)
library(ggplot2)
require("lazyeval")
```

```{r}
plotScatter <- function(data, x, y)
  ggplot(data = data, aes_string(x = x, y = y)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

simpleReg <- function(data, f)
{
  fit <- lm(f, data=df)
  summary(fit)
}
```

## C1-K401K

The data in 401K are a subset of data analyzed by Papke (1995) to study the rela- tionship between participation in a 401(k) pension plan and the generosity of the plan. The variable prate is the percentage of eligible workers with an active account; this is the variable we would like to explain. The measure of generosity is the plan match rate, mrate. This variable gives the average amount the firm contributes to each worker’s plan for each $1 contribution by the worker. For example, if mrate 5 0.50, then a $1 contribution by the worker is matched by a 50¢ contribution by the firm.

### Data

A data.frame with 1534 observations on 8 variables:

- prate: participation rate, percent
- mrate: 401k plan match rate
- totpart: total 401k participants
- totelg: total eligible for 401k plan
- age: age of 401k plan
- totemp: total number of firm employees
- sole: = 1 if 401k is firm’s sole plan
- ltotemp: log of totemp

```{r}
data('k401k')
```

(i) Find the average participation rate (`prate`) and the average match rate (`mrate`) in the sample of plans.

Avg prate : `r mean(k401k$prate)`

Avg mrate `r mean(k401k$mrate)`

(ii) Now, estimate the simple regression equation

$$\widehat{prate} =  \widehat{\beta}_0 + \widehat{\beta}_1 * mrate$$,
and report the results along with the sample size and R-squared.

```{r}
fit <- lm(prate~mrate, data=k401k)
summary(fit)

plotScatter(k401k, "mrate", "prate")
```

Sample size is `r nrow(k401k)`. $R^{2}$ value is `r round(summary(fit)$r.square, 4)`. Adjusted $R^{2}$ value is `r round(summary(fit)$adj.r.square, 4)`.

(iii) Interpret the intercept in your equation. Interpret the coefficient on mrate.

An increase in `mrate` is associated with a `r signif(abs(summary(fit)$coefficients["mrate", 1]), 3)` `r ifelse(summary(fit)$coefficients["mrate", 1] > 0, "increase", "decrease")` in the average `prate` and this effect is  ``r ifelse(summary(fit)$coefficients["mrate", 4] < 0.05, "is", "is not")` statistically significant at 1%`.

The intercept implies that, even if `mrate` = 0, the predicted participation rate is `r signif(abs(summary(fit)$coefficients["(Intercept)", 1]), 3)` percent.  The coefficient on `mrate` implies that a one-dollar increase in the match rate – a fairly large increase – is estimated to increase `prate` by `r signif(abs(summary(fit)$coefficients["mrate", 1]), 3)` percentage points.  This assumes, of course, that this change `prate` is possible (if, say, prate is already at 98, this interpretation makes no sense).

(iv) Find the predicted `prate` when `mrate` 3.5. Is this a reasonable prediction? Explain what is happening here.

```{r}
new <- data.frame(mrate = c(3.5))
predict(fit, new, se.fit = TRUE)

summary(fit)$coefficients["(Intercept)", 1] + 3.5 * summary(fit)$coefficients["mrate", 1]
```

This amount is impossible, as we can have at most a 100 percent participation rate.  This illustrates that, especially when dependent variables are bounded, a simple regression model can give strange predictions for extreme values of the independent variable.  In the sample of 1,534 firms, only 34 have mrate = 3.5.

(v) How much of the variation in `prate` is explained by `mrate`? Is this a lot in your opinion?

The Adjusted $R^{2}$ value is `r round(summary(fit)$adj.r.square, 4)`. This tells us that `r round(summary(fit)$adj.r.square*100, 2)`% of the variation in percentage of eligible workers with an active account, as quantified by `prate`, is explained by ``r attr(summary(fit)$terms,"term.labels")``.

`mrate` explains about `r round(summary(fit)$r.square * 100, 1)`% of the variation in `prate`.  This is not much, and suggests that many other factors influence 401(k) plan participation rates.

## C2-CEOSAL2

The data set in CEOSAL2 contains information on chief executive officers for U.S. corporations. The variable salary is annual compensation, in thousands of dollars, and ceoten is prior number of years as company CEO.

A data.frame with 177 observations on 15 variables:

- salary: 1990 compensation, $1000s
- age: in years
- college: =1 if attended college
- grad: =1 if attended graduate school
- comten: years with company
- ceoten: years as ceo with company
- sales: 1990 firm sales, millions
- profits: 1990 profits, millions
- mktval: market value, end 1990, mills.
- lsalary: log(salary)
- lsales: log(sales)
- lmktval: log(mktval)
- comtensq: comten^2
- ceotensq: ceoten^2
- profmarg: profits as percent of sales

```{r}
data('ceosal2')
```

(i) Find the average salary and the average tenure in the sample.

* Average salary (1990 compensation, $1000s)

```{r}
mean(ceosal2$salary)
```

* Average salary (log)

```{r}
mean(ceosal2$lsalary)
```

* Average tenure

```{r}
mean(ceosal2$ceoten)
```

(ii) How many CEOs are in their first year as CEO (that is, ceoten 5 0)? What is the longest tenure as a CEO?

* Number of CEOs in their first year as CEO

```{r}
ceosal2 %>% filter(ceoten == 0) %>% count()
```

* Longest tenure as a CEO

```{r}
max(ceosal2$ceoten)
```

(iii) Estimate the simple regression model $$log(salary) = \widehat{\beta}_0 + \widehat{\beta}_1 * ceoten + u$$,
and report your results in the usual form. What is the (approximate) predicted percentage increase in salary given one more year as a CEO?

Sample size is `r nrow(ceosal2)`.

```{r}
fit <- lm(lsalary~ceoten, data=ceosal2)
summary(fit)
```

```{r}
plotScatter(ceosal2, "ceoten", "lsalary")
```

<!-- The intercept implies that the estimated amount of sleep per week for someone who does not work is 3,586.4 minutes, or about 59.77 hours.  This comes to about 8.5 hours per night. -->

## C3-SLEEP75

Use the data in SLEEP75 from Biddle and Hamermesh (1990) to study whether there is a tradeoff between the time spent sleeping per week and the time spent in paid work. We could use either variable as the dependent variable. For concreteness, estimate the model
$$sleep = \widehat{\beta}_0 + \widehat{\beta}_1 * totwrk + u$$,
where sleep is minutes spent sleeping at night per week and totwrk is total minutes worked during the week.

A data.frame with 706 observations on 34 variables:

- age: in years
- black: =1 if black
- case: identifier
- clerical: =1 if clerical worker
- construc: =1 if construction worker
- educ: years of schooling
- earns74: total earnings, 1974
- gdhlth: =1 if in good or excel. health
- inlf: =1 if in labor force
- leis1: sleep - totwrk
- leis2: slpnaps - totwrk
- leis3: rlxall - totwrk
- smsa: =1 if live in smsa
- lhrwage: log hourly wage
- lothinc: log othinc, unless othinc < 0
- male: =1 if male
- marr: =1 if married
- prot: =1 if Protestant
- rlxall: slpnaps + personal activs
- selfe: =1 if self employed
- sleep: mins sleep at night, per wk
- slpnaps: minutes sleep, inc. naps
- south: =1 if live in south
- spsepay: spousal wage income
- spwrk75: =1 if spouse works
- totwrk: mins worked per week
- union: =1 if belong to union
- worknrm: mins work main job
- workscnd: mins work second job
- exper: age - educ - 6
- yngkid: =1 if children < 3 present
- yrsmarr: years married
- hrwage: hourly wage
- agesq: age^2

```{r}
data('sleep75')
```

```{r}
fit <- lm(sleep~totwrk, data=sleep75)
summary(fit)
```

(i) Report your results in equation form along with the number of observations and $R^{2}$. What does the intercept in this equation mean?

$$sleep = 3586.4 - 0.151 * totwrk$$,

Sample size is `r nrow(sleep75)`.  $R^{2}$ value is `r round(summary(fit)$r.square, 4)`. Adjusted $R^{2}$ value is `r round(summary(fit)$adj.r.square, 4)`.

The intercept implies that the estimated amount of sleep per week (`sleep`) for someone who does not work (`totwrk` = 0) is `r signif(summary(fit)$coefficients["(Intercept)", 1], 3)` minutes, or about `r signif(summary(fit)$coefficients["(Intercept)", 1]/60, 3)` hours.  This comes to about 8.5 hours per night.

(ii) If totwrk increases by 2 hours, by how much is sleep estimated to fall? Do you find this to be a large effect?

If someone works two more hours per week then totwrk = 120 (totwrk is measured in minutes not hours).  The amount of sleep would decrease by `r signif(summary(fit)$coefficients["totwrk", 1], 3)`(120) = `r signif(summary(fit)$coefficients["totwrk", 1]*120, 3)` minutes.  

```{r}
new <- data.frame(totwrk = c(120))
predict(fit, new, se.fit = TRUE)
```

```{r}
120 * summary(fit)$coefficients["totwrk", 1]
```

```{r}
plotScatter(sleep75, "totwrk", "sleep")
```

## C4-WAGE2

Use the data in WAGE2 to estimate a simple regression explaining monthly salary (wage) in terms of IQ score (IQ).

A data.frame with 935 observations on 17 variables:

- wage: monthly earnings
- hours: average weekly hours
- IQ: IQ score
- KWW: knowledge of world work score
- educ: years of education
- exper: years of work experience
- tenure: years with current employer
- age: age in years
- married: =1 if married
- black: =1 if black
- south: =1 if live in south
- urban: =1 if live in SMSA
- sibs: number of siblings
- brthord: birth order
- meduc: mother’s education
- feduc: father’s education
- lwage: natural log of wage

```{r}
data('wage2')
```

(i) Find the average salary and average IQ in the sample. What is the sample standard deviation of IQ? (IQ scores are standardized so that the average in the population is 100 with a standard deviation equal to 15.)

```{r}
mean(wage2$wage)
```

```{r}
mean(wage2$IQ)
```

```{r}
sd(wage2$IQ)
```

(ii) Estimate a simple regression model where a one-point increase in IQ changes wage by a constant dollar amount. Use this model to find the predicted increase in wage for an increase in IQ of 15 points. Does IQ explain most of the variation in wage?


```{r}
fit <- lm(wage~IQ, data=wage2)
summary(fit)
```

Sample size is `r nrow(wage2)`.  $R^{2}$ value is `r round(summary(fit)$r.square, 4)`. Adjusted $R^{2}$ value is `r round(summary(fit)$adj.r.square, 4)`.

```{r}
plotScatter(wage2, "IQ", "wage")
```

Estimate a simple regression model where a one-point increase in IQ changes wage by a constant dollar amount. Use this model to find the predicted increase in wage for an increase in IQ of 15 points. Does IQ explain most of the variation in wage?

```{r}
new <- data.frame(IQ = c(15))
predict(fit, new, se.fit = TRUE)
```

(iii) Now, estimate a model where each one-point increase in IQ has the same percent- age effect on wage. If IQ increases by 15 points, what is the approximate percent- age increase in predicted wage?


## C5-RDCHEM

For the population of firms in the chemical industry, let rd denote annual expenditures on research and development, and let sales denote annual sales (both are in millions of dollars).

A data.frame with 32 observations on 8 variables:

- rd: R&D spending, millions
- sales: firm sales, millions
- profits: profits, millions
- rdintens: rd as percent of sales
- profmarg: profits as percent of sales
- salessq: sales^2
- lsales: log(sales)
- lrd: log(rd)

```{r}
data('rdchem')
```

(i) Write down a model (not an estimated equation) that implies a constant elasticity between rd and sales. Which parameter is the elasticity?

The constant elasticity model is a log-log model: $$ log(rd) = \beta_0 + \beta_1 * log(sales) $$ where $\beta_1$ is the elasticity of `rd` with respect to `sales`.

```{r}
fit <- lm(lrd~lsales, data=rdchem)
summary(fit)
```

(ii) Now, estimate the model using the data in RDCHEM.RAW. Write out the estimated equation in the usual form. What is the estimated elasticity of rd with respect to sales? Explain in words what this elasticity means.

```{r}
fit <- lm(lrd~lsales, data=rdchem)
summary(fit)
```

The estimated equation is: $$ log(rd) = -4.105 + 1.076 * log(sales) $$

The estimated elasticity of `rd` with respect to sales is `r signif(summary(fit)$coefficients["lsales", 1], 3)`, which is just above one.  A one percent increase in `sales` is estimated to increase `rd` by about `r signif(summary(fit)$coefficients["lsales", 1], 2)`%.

## C6-MEAP93

We used the data in MEAP93 for Example 2.12. Now we want to explore the relationship between the math pass rate (math10) and spending per student (expend).

A data.frame with 408 observations on 17 variables:

- lnchprg: perc of studs in sch lnch prog
- enroll: school enrollment
- staff: staff per 1000 students
- expend: expend. per stud, $
- salary: avg. teacher salary, $
- benefits: avg. teacher benefits, $
- droprate: school dropout rate, perc
- gradrate: school graduation rate, perc
- math10: perc studs passing MEAP math
- sci11: perc studs passing MEAP science
- totcomp: salary + benefits
- ltotcomp: log(totcomp)
- lexpend: log of expend
- lenroll: log(enroll)
- lstaff: log(staff)
- bensal: benefits/salary
- lsalary: log(salary)

```{r}
data('meap93')
```

(i) Do you think each additional dollar spent has the same effect on the pass rate, or
does a diminishing effect seem more appropriate? Explain.

* Additional dollar spent does not have same effect on the pass rate.  I expect diminishing effect.

```{r}
fit <- lm(math10~expend, data=meap93)
summary(fit)
```

```{r}
plotScatter(meap93, "expend", "math10")
```

(ii) In the population model $$math10 + \widehat{\beta}_0 + \widehat{\beta}_1 log(expend ) + u$$,
argue that b1/10 is the percentage point change in math10 given a 10% increase in expend.


$$\beta_1 /10$$ is the percentage point change in `math10` given a 10% increase in `expend`.

```{r}
fit <- lm(math10~lexpend, data=meap93)
summary(fit)
```

(iii) Use the data in MEAP93 to estimate the model from part (ii). Report the estimated equation in the usual way, including the sample size and R-squared.

A 10% increase in `expendidure` is associated with a `r signif(abs(summary(fit)$coefficients["lexpend", 1]), 3)` `r ifelse(summary(fit)$coefficients["lexpend", 1] > 0, "increase", "decrease")` in the average perc studs passing MEAP math and this effect is ``r ifelse(summary(fit)$coefficients["lexpend", 4] < 0.1, "is", "is not")` statistically significant at 1%`.

```{r}
plotScatter(meap93, "lexpend", "math10")
```

(iv) How big is the estimated spending effect? Namely, if spending increases by 10%, what is the estimated percentage point increase in math10?

(v) One might worry that regression analysis can produce fitted values for math10 that are greater than 100. Why is this not much of a worry in this data set?

## C7-CHARITU

Use the data in CHARITY [obtained from Franses and Paap (2001)] to answer the following questions:

A data.frame with 4268 observations on 8 variables:

- respond: =1 if responded with gift
- gift: amount of gift, Dutch guilders
- resplast: =1 if responded to most recent mailing
- weekslast: number of weeks since last response
- propresp: response rate to mailings
- mailsyear: number of mailings per year
- giftlast: amount of most recent gift
- avggift: average of past gifts

```{r}
data('charity')
```

(i) What is the average gift in the sample of 4,268 people (in Dutch guilders)? What percentage of people gave no gift?

* Average gift (Dutch guilders) and % of people that gave no gift

```{r}
mean(charity$gift)
mean(!charity$respond)
```

The average gift is about `r mean(charity$gift)` Dutch guilders. Out of `r nrow(charity)` respondents, `r nrow(charity %>% filter(respond == 0))` did not give a gift, or about `r round(mean(!charity$respond)*100, 0)` percent.

(ii) What is the average mailings per year? What are the minimum and maximum values?

* Average, min and max mailing per year

```{r}
mean(charity$mailsyear)
min(charity$mailsyear)
max(charity$mailsyear)
```

The average mailings per year is about `r round(mean(charity$mailsyear),2)`. The minimum value is `r min(charity$mailsyear)` (which presumably means that someone has been on the mailing list for at least four years) and the maximum value is `r max(charity$mailsyear)`.

(iii) Estimate the model $$gift = \widehat{\beta}_0 + \widehat{\beta}_1 * mailsyear + u$$
by OLS and report the results in the usual way, including the sample size and R-squared.


```{r}
fit <- lm(gift~mailsyear, data=charity)
summary(fit)
```

Sample size is `r nrow(charity)`.  $R^{2}$ value is `r round(summary(fit)$r.square, 4)`. Adjusted $R^{2}$ value is `r round(summary(fit)$adj.r.square, 4)`.

```{r}
plotScatter(charity, "mailsyear", "gift")
```

(iv) Interpret the slope coefficient. If each mailing costs one guilder, is the charity expected to make a net gain on each mailing? Does this mean the charity makes a net gain on every mailing? Explain.

The estimated equation is  $$gift = 2.0141 + 2.6495 * mailsyear$$

The slope coefficient means that each mailing per year is associated with an estimated `r signif(summary(fit)$coefficients["mailsyear", 1], 3)` additional guilders, on average. Therefore, if each mailing costs one guilder, the expected profit from each mailing is estimated to be `r signif(summary(fit)$coefficients["mailsyear", 1], 3)` guilders. This is only the average, however. 

<!-- Some mailings generate no contributions, or a contribution less than the mailing cost; other mailings generated much more than the mailing cost. -->

(v) What is the smallest predicted charitable contribution in the sample? Using this simple regression analysis, can you ever predict zero for gift?

Min gift where some people have received 0.25 mailings: `r charity %>% filter(mailsyear == 0.25) %>% select(gift) %>% summarise(mean = min(gift))`

```{r}
new <- data.frame(mailsyear = c(0))
predict(fit, new, se.fit = TRUE)
```

```{r}
new <- data.frame(mailsyear = c(min(charity$mailsyear)))
x1 <- predict(fit, new, se.fit = TRUE)
```

The smallest mailsyear in the sample is `r min(charity$mailsyear)`. The smallest predicted value of gifts is 2.01 + 2.65 (.25) = `r round(x1$fit,2)`. With this estimated equation, we never predict zero charitable gifts.

## C8

To complete this exercise you need a software package that allows you to generate data from the uniform and normal distributions.

(i) Start by generating 500 observations xi – the explanatory variable – from the uniform distribution with range [0,10]. (Most statistical packages have a command for the Uniform[0,1] distribution; just multiply those observations by 10.) What are the sample mean and sample standard deviation of the xi?

The expected mean is about 5.

```{r}
x <- runif(500, min = 0, max = 10)
mean(x)
sd(x)
```

(ii) Randomly generate 500 errors, ui, from the Normal[0,36] distribution. (If you generate a Normal[0,1], as is commonly available, simply multiply the outcomes by six.) Is the sample average of the ui exactly zero? Why or why not? What is the sample standard deviation of the ui?

The expected mean is about 18.

```{r}
u <- runif(500, min = 0, max = 36)
mean(u)
sd(u)
```


```{r}
df <- data.frame(x,u)
df$y <- 1 + df$x * 2 + df$u
df$y1 <- df$x + df$u
```

(iii) Now generate the yi as $$y_i = 1 + 2x_i + u_i = \widehat{\beta}_0 + \beta x_i + ui$$;
that is, the population intercept is one and the population slope is two. Use the data to run the regression of yi on xi. What are your estimates of the intercept and slope? Are they equal to the population values in the above equation? Explain.


(iv) Obtain the OLS residuals, uˆi, and verify that equation (2.60) hold (subject to rounding error).

(v) Compute the same quantities in equation (2.60) but use the errors ui in place of the residuals. Now what do you conclude?

(vi) Repeat parts (i), (ii), and (iii) with a new sample of data, starting with generating the xi. Now what do you obtain for bˆ0 and bˆ1? Why are these different from what you obtained in part (iii)?

```{r}
fit <- lm(y~x, data=df)
summary(fit)

plotScatter(df, "x", "y")

fit <- lm(y1~x, data=df)
summary(fit)

plotScatter(df, "x", "y1")
```


## C9-countymurders

A data.frame with 37349 observations on 20 variables:
- arrests: # of murder arrests
- countyid: county identifier: 1000*statefips + countyfips
- density: population density; per square mile
- popul: county population
- perc1019: percent pop. age 10-19
- perc2029: percent pop. age 20-29
- percblack: percent population black
- percmale: percent population male
- rpcincmaint: real per capita income maintenance
- rpcpersinc: real per capita personal income
- rpcunemins: real per capita unem insurance payments
- year: 1980-1996
- murders: # of murders
- murdrate: murders per 10,000 people
- arrestrate: murder arrests per 10,000
- statefips: state FIPS code
- countyfips: county FIPS code
- execs: # of executions
- lpopul: log(popul)
- execrate: executions per 10,000

```{r}
data('countymurders')
```

```{r}
countymurders %>% filter(year ==  1996 & murders == 0) %>% count()
```

```{r}
countymurders %>% filter(year ==  1996 & execs > 0) %>% count()
```

```{r}
countymurders %>% filter(year ==  1996 & execs > 0) %>% select(execs) %>% summarise(max_execs = max(execs))

```

```{r}
fit <- lm(murders~execs, data=countymurders %>% filter(year ==  1996))
summary(fit)
```

```{r}
plotScatter(countymurders %>% filter(year ==  1996), "execs", "murders")
```

```{r}
new <- data.frame(execs = c(0))
predict(fit, new, se.fit = TRUE)

summary(fit)$coefficients["(Intercept)", 1] + 0 * summary(fit)$coefficients["execs", 1]
```

## C10-CATHOLIC

A data.frame with 7430 observations on 13 variables:
- id: person identifier
- read12: reading standardized score
- math12: mathematics standardized score
- female: =1 if female
- asian: =1 if Asian
- hispan: =1 if Hispanic
- black: =1 if black
- motheduc: mother’s years of education
- fatheduc: father’s years of education
- lfaminc: log of family income
- hsgrad: =1 if graduated from high school by 1994
- cathhs: =1 if attended Catholic HS
- parcath: =1 if a parent reports being Catholic

```{r}
data('catholic')
```

Sample size

```{r}
catholic %>% count()
```

Means and standard deviation for math12 and read12

```{r}
catholic %>% summarise(math12_mean = mean(math12), math12_sd = sd(math12), read12_mean = mean(read12), read12_sd = sd(read12))
```


```{r}
fit <- lm(math12~read12, data=catholic)
summary(fit)
```

```{r}
plotScatter(catholic, "read12", "math12")
```

An increase in `reading standardized score` is associated with a `r signif(abs(summary(fit)$coefficients["read12", 1]), 3)` `r ifelse(summary(fit)$coefficients["read12", 1] > 0, "increase", "decrease")` in the average `mathematics standardized score` and this effect is  ``r ifelse(summary(fit)$coefficients["read12", 4] < 0.1, "is", "is not")` statistically significant at 1%`.

```{r}
fit <- lm(read12~math12, data=catholic)
summary(fit)
```

```{r}
plotScatter(catholic, "math12", "read12")
```

